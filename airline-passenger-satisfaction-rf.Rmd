---
title: Airline Passenger Satisfaction Parameter Tuning
output: html_document
---

# Title: Airline Passenger Satisfaction Parameter Tuning

# Authors: Maike Hucht, Jule Lang, Micahel Prendota, Deniz Terzioglu

# Date: April 21, 2024

In this notebook, we'll explore a dataset containing information about airline passengers and their satisfaction levels. We'll preprocess the data, build machine learning models (Decision Tree and Random Forest), and evaluate their performance.

## Setup

```{r}
# Load libraries
library(tidyverse)
library(caret)
library(randomForest)
```

## Data Loading and Preprocessing

Importing the data

```{r}
data <- read.csv('/kaggle/input/airline-passenger-satisfaction/train.csv')
head(data)
summary(data)
```

Removing unwanted columns

```{r}
data <- data %>% 
  select(-c(Unnamed.0, id))
```

Handling missing values

```{r}
data$`Arrival Delay in Minutes`[is.na(data$`Arrival Delay in Minutes`)] <- mean(data$`Arrival Delay in Minutes`, na.rm = TRUE)
```

Encoding categorical variables

```{r}
data$Gender <- ifelse(data$Gender == 'Male', 1, 0)
data$`Customer Type` <- ifelse(data$`Customer Type` == 'Loyal Customer', 1, 0)
data$`Type of Travel` <- ifelse(data$`Type of Travel` == 'Business travel', 1, 0)
data$Class <- ifelse(data$Class == 'Business', 1, ifelse(data$Class == 'Eco', 0, -1))
data$satisfaction <- ifelse(data$satisfaction == 'neutral or dissatisfied', 1, 0)
```

Splitting into train and test sets

```{r}
set.seed(23)
train_index <- createDataPartition(data$satisfaction, p = 0.8, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]

x_train <- train_data %>% 
  select(-satisfaction)
y_train <- train_data$satisfaction

x_test <- test_data %>% 
  select(-satisfaction)
y_test <- test_data$satisfaction
```

## Model Building and Training

### Decision Tree

Training the Decision Tree model with a tune grid

```{r}
DT_model <- train(
  x = x_train,
  y = y_train,
  method = "rpart",
  tuneGrid = data.frame(
    cp = c(0.01, 0.05, 0.1)
  )
)
```

Making predictions

```{r}
DT_pred <- predict(DT_model, newdata = x_test)
```

Evaluating model performance

```{r}
acc_dt <- confusionMatrix(DT_pred, y_test)$overall['Accuracy']
acc_dt
```

### Random Forest

Training the Random Forest model with a tune grid

```{r}
RF_model <- train(
  x = x_train,
  y = y_train,
  method = "rf",
  tuneGrid = data.frame(
    mtry = c(2, 4, 6),
    nodesize = c(1, 5, 10)
  )
)
```

Making predictions

```{r}
RF_pred <- predict(RF_model, newdata = x_test)
```

Evaluating model performance

```{r}
acc_rf <- confusionMatrix(RF_pred, y_test)$overall['Accuracy']
acc_rf
```

## Conclusion

In this notebook, we built and evaluated machine learning models (Decision Tree and Random Forest) to predict airline passenger satisfaction levels. The Random Forest model achieved a higher accuracy compared to the Decision Tree model.

You can copy this markdown content into a Jupyter notebook and execute it with the appropriate kernel (R kernel) to run the R code snippets. Let me know if you need further assistance!
